{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an image classifier using a pre-trained model\n",
    "\n",
    "In this network we will look at how to train basic image classifier from scratch in PyTorch.\n",
    "\n",
    "**Before you go any further** follow the instructions in the file `create-classification-dataset.ipynb` to make you dataset before you can train anything here. \n",
    "\n",
    "Start with the other notebook `train-image-classifier-from-scratch.pynb` before moving onto this one. Complete all the tasks there before working through this notebook.\n",
    "\n",
    "You will want to wait until that has trained before running this notebook. \n",
    "\n",
    "First lets do some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are getting an error you may need to uncomment the next line to install sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters\n",
    "\n",
    "Now lets define out hyperparameters. **If your dataset has more than 3 classes** make sure to change the parameter `num_classes`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "momentum = 0.9\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "val_size = 0.3\n",
    "batch_size = 100\n",
    "learn_rate = 0.001\n",
    "freeze_lower_layers = True\n",
    "data_path = '../data/my-data/my-classification-dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training image transforms\n",
    "\n",
    "Here we define our image transforms (and data augmentation) for our training data. There is a task in the other notebook to write comments for these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomAffine(degrees=(-30,30),translate=(0.15,0.15),scale=(0.85,1.15)),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        transforms.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation image transforms\n",
    "\n",
    "Here we define our image transforms for our validation data. How do they differ from the training transforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose(\n",
    "    [   \n",
    "        torchvision.transforms.Resize(224, antialias=True),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create datasets\n",
    "\n",
    "Here we create our dataset classes. Because we are using different transforms, we need to make two seperate dataset classes. We will then take a random sub-selection of our data and split our dataset into two. \n",
    "\n",
    "When we do the split, by setting `random_state=42`, we are doing this in a deterministic way, such that we will always get the same 'random' split of data into the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate train and validation dataset with seperate transforms\n",
    "train_dataset = ImageFolder(data_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(data_path, transform=val_transform)\n",
    "\n",
    "# Get length of dataset and indicies\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# Get train / val split for data points\n",
    "train_indices, val_indices = train_test_split(indices, test_size=val_size, random_state=42)\n",
    "\n",
    "# Override dataset classes to only be samples for each split\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, val_indices)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training images\n",
    "\n",
    "Here we are plotting a sample of training images. See how the data augmentation transforms are manipulating the images, compared to the images in the validation set (visualised in the next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot validation set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(val_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Validation Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model\n",
    "\n",
    "Instead of creating our own convolution neural network from scratch, here we are downloading a pre-trained model from [the torchvision models library](https://pytorch.org/vision/stable/models.html). Here we are using a [ResNet](https://arxiv.org/abs/1512.03385) trained on [the imagenet dataset](https://www.image-net.org/), but feel free to change tho one of the many other available models from the torchvison library if you want.\n",
    "\n",
    "The boolean `freeze_lower_layers` that you can change in the [hyperparamers](#hyperparameters) cell determines whether we freeze the weights of most of the CNN. If this is set to `True` then we are performing **transfer learning** (only learning a new set of weights for the final layer). If this is set to `False` then we are performing **fine-tuning**, where we fine-tune the weights of the whole model from an initial set of pre-trained weights.\n",
    "\n",
    "The following block of code is originally sourced from: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze weights\n",
    "if freeze_lower_layers == True:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup loss and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss for training classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Stochastic gradient descent loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop\n",
    "\n",
    "Here is our training loop for our data. Just like the other notebook, look at how the training dataset and validation dataset are used? \n",
    "\n",
    "What differences are there in the code when we cycle through each of these sets of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_loss = 100000\n",
    "for epoch in range(num_epochs): \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get data\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Process data\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Update model weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Normalise cumulative losses to dataset size\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Added cumulative losses to lists for later display\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, train loss: {train_loss:.3f}, val loss: {val_loss:.3f}')\n",
    "    \n",
    "    # if validation score is lowest so far, save the model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_finetuned_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training vs validation loss \n",
    "\n",
    "Lets plot our training vs validation loss over time. If you train for long enough you will usually see the validation loss start to get worse at some point while the training loss will continue to get better. This occurs when the model starts to **overfit** to the training data, and become worse at accurately classifying unseen data. \n",
    "\n",
    "When our model is giving the best performance on our validation data (before the validation loss starts to increase) is when we would perform early stopping. If you haven't observed that here, you may need to re-run this code and train for more epochs. Given the limited time available in class, you may want to do this at home, running the code overnight (with your laptop plugged in!)\n",
    "\n",
    "**Compare the losses here with the other notebook.** How does the overall magnitude of the loss compare? Does this approach appear to learn faster or slower than the other notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train vs validation loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "**Task 1:** Run all the cells in this code to train a classifier on your custom dataset. \n",
    "\n",
    "**Task 2:** Once it has trained compare the results with the notebook `train-image-classifier-from-scratch.ipynb`, which approach gives you the lower overall loss and which converges faster?\n",
    "\n",
    "#### Bonus tasks\n",
    "**Task A:** [Change the hyperparameter](#hyperparameters) `freeze_lower_layers` from `True` to `False` to perform **fine-tuning** instead of **transfer learning** and re-run the code (make a copy of this notebook if you want to have a direct comparison). How does the results compare? Is this approach noticably slower?\n",
    "\n",
    "**Task B:** [Change the CNN model loaded from torchvision library](#load-pre-trained-model) from a ResNet18 to another ResNet model. How does that affect the training peformance? (Again you may want to make a copy of this notebook for a direct comparison.) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
