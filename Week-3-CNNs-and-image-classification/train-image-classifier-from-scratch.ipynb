{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an image classifier from scratch\n",
    "\n",
    "In this network we will look at how to train basic image classifier from scratch in PyTorch.\n",
    "\n",
    "**Before you go any further** follow the instructions in the file `create-classification-dataset.ipynb` to make you dataset before you can train anything here. \n",
    "\n",
    "Work your way through this notebook, running each cell and looking carefully at what the code is doing. There are some tasks at the bottom of the notebook. \n",
    "\n",
    "Once you run this code, you can compare it with the code in the notebook `train-image-classifier-from-pretrained.pynb`. \n",
    "\n",
    "First lets do some imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are getting an error you may need to uncomment the next line to install sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters\n",
    "\n",
    "Now lets define our hyperparameters. **If your dataset has more than 3 classes** make sure to change the parameter `num_classes`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "momentum = 0.9\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "val_size = 0.3\n",
    "batch_size = 100\n",
    "learn_rate = 0.001\n",
    "data_path = '../data/my-data/my-classification-dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training image transforms\n",
    "\n",
    "Here we define our image transforms (and data augmentation) for our training data. Once you have started to train your model, come back to this cell for task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        #\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #\n",
    "        transforms.RandomAffine(degrees=(-30,30),translate=(0.25,0.25),scale=(0.85,1.15)),\n",
    "        #\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        #\n",
    "        transforms.RandomResizedCrop(size=(64, 64), antialias=True),\n",
    "        #\n",
    "        transforms.ToTensor(),\n",
    "        #\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation image transforms\n",
    "\n",
    "Here we define our image transforms for our validation data. How do they differ from the training transforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose(\n",
    "    [   \n",
    "        torchvision.transforms.Resize(64, antialias=True),\n",
    "        torchvision.transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create datasets\n",
    "\n",
    "Here we create our dataset classes. Because we are using different transforms, we need to make two seperate dataset classes. We will then take a random sub-selection of our data and split our dataset into two. \n",
    "\n",
    "When we do the split, by setting `random_state=42`, we are doing this in a deterministic way, such that we will always get the same 'random' split of data into the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate train and validation dataset with seperate transforms\n",
    "train_dataset = ImageFolder(data_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(data_path, transform=val_transform)\n",
    "\n",
    "# Get length of dataset and indicies\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# Get train / val split for data points\n",
    "train_indices, val_indices = train_test_split(indices, test_size=val_size, random_state=42)\n",
    "\n",
    "# Override dataset classes to only be samples for each split\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, val_indices)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training images\n",
    "\n",
    "Here we are plotting a sample of training images. See how the data augmentation transforms are manipulating the images, compared to the images in the validation set (visualised in the next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot validation set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(val_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Validation Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define convolutional neural network\n",
    "\n",
    "Here we define our convolutional neural network. Once you have started to train your model, come back to this cell for task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here we define our class for our CNN based classifier\n",
    "#  This model takes images and input and gives a prediction over the classes provided in the training data\n",
    "class ClassificationNetwork(nn.Module):\n",
    "    # Constructor for the class\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the base class nn.module\n",
    "        super().__init__()\n",
    "        # First convolutional layer\n",
    "        # Takes a 3D tensor with 3 channels as input (3 colour channels in the image)\n",
    "        # Outputs a 3D tensor with 64 channels (outputs of convolutional filters)\n",
    "        # The convolutional kernel size is 5x5 \n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        # Second convolutional layer\n",
    "        # Takes a 3D tensor with 64 channels as input \n",
    "        # Outputs a 3D tensor with 128 channels (outputs of convolutional filters)\n",
    "        # The convolutional kernel size is 5x5 \n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        # Third convolutional layer\n",
    "        # Takes a 3D tensor with 128 channels as input \n",
    "        # Outputs a 3D tensor with 128 channels \n",
    "        # The convolutional kernel size is 5x5 \n",
    "        self.conv3 = nn.Conv2d(128, 128, 5)\n",
    "        # Max-pooling function \n",
    "        # This is reused through the network in the forward pass\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # First fully connected layer\n",
    "        # Takes a vector of 2048 as input and outputs a vector of 256\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        # Second fully connected layer\n",
    "        # Takes a vector of 256 as input and outputs a vector of class predictions\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    # Definition of the forward pass\n",
    "    # Here the classifier takes an image as input and predicts an vector of probabilites, one for each class in  our dataset\n",
    "    def forward(self, x):\n",
    "        # Pass input through first convolutional layer with relu activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Use max-pooling to downsample the output of the first conv layer\n",
    "        x = self.pool(x)\n",
    "        # Pass output of maxpooling through second convolutional layer with relu activation function\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Use max-pooling to downsample the output of the first conv layer\n",
    "        x = self.pool(x)\n",
    "        # Pass output of maxpooling through third convolutional layer with relu activation function\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # Use max-pooling to downsample the output of the first conv layer\n",
    "        x = self.pool(x)\n",
    "        # Flatten the output of the last maxpooling operation into a vector of size 2048\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Pass vector through first fully connected layer with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Pass vector through second fully connected layer (no activation function needed here)\n",
    "        x = self.fc2(x)\n",
    "        # Output vector of class probabilities\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup core objects\n",
    "\n",
    "Here we setup our core objects, the model, the loss function and the optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNetwork()\n",
    "model.to(device)\n",
    "\n",
    "# Cross entropy loss for training classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Stochastic gradient descent loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop\n",
    "\n",
    "Here is our training loop for our data. Look at how the training dataset and validation dataset are used? \n",
    "\n",
    "What differences are there in the code when we cycle through each of these sets of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_loss = 100000\n",
    "for epoch in range(num_epochs): \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get data\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Process data\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Update model weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Normalise cumulative losses to dataset size\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Added cumulative losses to lists for later display\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, train loss: {train_loss:.3f}, val loss: {val_loss:.3f}')\n",
    "    \n",
    "    # if validation score is lowest so far, save the model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_from_scratch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training vs validation loss \n",
    "\n",
    "Lets plot our training vs validation loss over time. If you train for long enough you will usually see the validation loss start to get worse at some point while the training loss will continue to get better. This occurs when the model starts to **overfit** to the training data, and become worse at accurately classifying unseen data. \n",
    "\n",
    "When our model is giving the best performance on our validation data (before the validation loss starts to increase) is when we would perform early stopping. If you haven't observed that here, you may need to re-run this code and train for more epochs. Given the limited time available in class, you may want to do this at home, running the code overnight (with your laptop plugged in!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train vs validation loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "**Task 1:** Run all the cells in this code to train a classifier on your custom dataset. While this is training, you can do tasks 2 and 3.\n",
    "\n",
    "**Task 2:** Go to [the cell that defines the training transformations](#training-image-transforms) and look at that code. Write a comment for every line to describe what the code is doing. If you are unsure you can consult [the pytorch reference](https://pytorch.org/vision/0.9/transforms.html).\n",
    "\n",
    "**Task 3:** Go to [the cell that defines the convolutional neural network](#define-convolutional-neural-network) and look at that code. Based on the material from the lecture try to write a comment for each line of code in this cell. Consult [the pytorch neural network (torch.nn) reference](https://pytorch.org/docs/stable/nn.html) and [the W3 schools reference on python inheritance](https://www.w3schools.com/python/python_inheritance.asp) for any code that you are unsure about. \n",
    "\n",
    "**Task 4:** Go the to the notebook `train-image-classifier-from-pretrained.ipynb` and run the code in there to train a model. Compare the code in this notebook to that? Where does the code differ? Compare the losses in training, which approach was quicker to converge onto an accurate model?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
